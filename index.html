<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html> <!--<![endif]-->
<!-- testing commit -->
<head>
<meta charset="utf-8">
<title>CVPR 2020 Workshop On Towards Human-Centric Image/Video Synthesis, and the 4th Look Into Person (LIP) Challenge</title>
<meta name="description" content="Towards Human-Centric Image/Video Synthesis, and the 4th Look Into Person (LIP) Challenge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no">
<!--<meta name="keywords" content="Visual Understanding of Humans in Crowd Scene, lip,LIP, Look Into Person,CVPR,cvpr,cvpr2017,cvpr workshop,XiaoDan Liang,ShenHua Gao,"> -->   
<link rel="stylesheet" href="css/bootstrap.min.css">
    
<!-- Main CSS -->
<link rel="stylesheet" href="css/main.css">        
<!-- Fonts -->
<link rel="stylesheet" href="css/icon/font-awesome.css">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900" rel="stylesheet"> 
<!-- Linea Basic -->
<link rel="stylesheet" href="css/icon/lineabasic.css">        
<!-- Animate.css -->
<link rel="stylesheet" href="css/animate.min.css">
<!-- Magnific Popup -->
<link rel="stylesheet" href="css/magnific-popup.css">
<!-- style -->
<link rel="stylesheet" href="css/style.css">

  <link rel="icon" href="img/favicon.ico">

<script src="js/vendor/modernizr.js"></script>


</head>
<body id="home" data-spy="scroll" data-offset="50" data-target=".navbar-default">

<!-- Preloader -->
<div class="preloader">
  <div class="preloader10">
    <span></span>
    <span></span>
  </div>
</div>


<!-- Navbar -->
<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    <div class="row">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a target="_blank" href="http://cvpr2020.thecvf.com/">
          <img src="img/CVPRLogo2020.jpg" alt="FOLIO LOGO" style=" height:60px;" />
        </a>
        <a target="_blank" href="https://vuhcs.github.io/">
          <img src="img/logo2.png" alt="FOLIO LOGO" />
        </a>
      </div>
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1" >
        <ul class="nav navbar-nav navbar-right" style="padding-top:10px;">
          <li><a href="#home">Home</a></li>
          <!--<li><a href="#portfolio">Introduction</a></li>-->
          <!--<li><a href="#acceptedpapers">Accepted Papers</a></li>-->
          <!--<li><a href="#winners">Winners</a></li>-->
          <!--<li><a href="#poster">Posters</a></li>-->
          <li><a href="#papers"><strong>Call for Papers</strong></a></li>
          <!--<li><a href="#challenge"><strong>Challenges</strong></a></li>-->
          <!--<li><a href="#about">Topics</a></li>-->
          
          <li><a href="#blog">Schedule</a></li>
          <li><a href="#team">Organizers</a></li>
          <!--<li><a href="#association">Contact</a></li>-->
          <li class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#history">History <span class="caret"></span></a>
            <ul class="dropdown-menu">
              <li><a href="vuhcs-2019/index.html" target="_blank">VUHCS-2019</a></li>
              <li><a href="vuhcs-2018/index.html" target="_blank">VUHCS-2018</a></li>
              <li><a href="vuhcs-2017/index.html" target="_blank">VUHCS-2017</a></li>
            </ul>
          </li>
        </ul>
      </div>
    </div>
  </div>
</nav>



<!-- Header -->
<header id="revolution-home" class="revolution-home">
  <div id="rev_slider_490_1_wrapper" class="rev_slider_wrapper fullwidthbanner-container" data-alias="image-hero39" data-source="gallery" style="margin:0px auto;background-color:transparent;padding:0px;margin-top:0px;margin-bottom:0px;">
    <!-- START REVOLUTION SLIDER 5.3.0.2 fullwidth mode -->
      <div id="rev_slider_490_1" class="rev_slider fullwidthabanner" style="display:none;" data-version="5.3.0.2">
    <ul>    <!-- SLIDE  -->
      <li data-index="rs-1699" data-transition="zoomout" data-slotamount="default" data-hideafterloop="0" data-hideslideonmobile="off"  data-easein="Power4.easeInOut" data-easeout="Power4.easeInOut" data-masterspeed="2000"  data-thumb="img/sliders/SaltLake-100x50.jpg"  data-rotate="0"  data-saveperformance="off"  data-title="Intro" data-param1="" data-param2="" data-param3="" data-param4="" data-param5="" data-param6="" data-param7="" data-param8="" data-param9="" data-param10="" data-description="">
        <!-- MAIN IMAGE -->
        <img style="max-width:100% ! important;" src="img/CVPR2020_banner.jpg"  alt=""  data-bgposition="center center" data-bgfit="cover" data-bgrepeat="no-repeat" data-bgparallax="10" class="rev-slidebg" data-no-retina>
        <!-- LAYERS -->

        <!-- LAYER NR. 1 -->
        <div class="tp-caption tp-shape  " 
           id="slide-1699-layer-10" 
           data-x="['center','center','center','center']" data-hoffset="['0','0','0','0']" 
           data-y="['middle','middle','middle','middle']" data-voffset="['0','0','0','0']" 
                data-width="full"
          data-height="full"
          data-whitespace="nowrap"
        
          data-type="shape" 
          data-basealign="slide" 
          data-responsive_offset="on" 
          data-responsive="off"
          data-frames='[{"from":"opacity:0;","speed":1500,"to":"o:1;","delay":750,"ease":"Power3.easeInOut"},{"delay":"wait","speed":300,"ease":"nothing"}]'
          data-textAlign="['left','left','left','left']"
          data-paddingtop="[0,0,0,0]"
          data-paddingright="[0,0,0,0]"
          data-paddingbottom="[0,0,0,0]"
          data-paddingleft="[0,0,0,0]"

          style="z-index: 5;text-transform:left;background-color:rgba(0, 0, 0, 0.40);border-color:rgba(0, 0, 0, 0.50);border-width:0px; max-width:100% ! important;"> </div>

        <!-- LAYER NR. 3 -->
        <div class="tp-caption NotGeneric-Title   tp-resizeme" 
           id="slide-1699-layer-1" 
           data-x="['center','center','center','center']" data-hoffset="['0','0','0','0']" 
           data-y="['middle','middle','middle','middle']" data-voffset="['0','0','-22','-29']" 
                data-fontsize="['70','70','70','50']"
          data-lineheight="['70','70','70','50']"
          data-width="none"
          data-height="none"
          data-whitespace="nowrap"
     
          data-type="text" 
          data-responsive_offset="on" 

          data-frames='[{"from":"z:0;rX:0deg;rY:0;rZ:0;sX:1.5;sY:1.5;skX:0;skY:0;opacity:0;","mask":"x:0px;y:0px;","speed":1500,"to":"o:1;","delay":1000,"ease":"Power3.easeInOut"},{"delay":"wait","speed":1000,"to":"y:[100%];","mask":"x:inherit;y:inherit;","ease":"Power2.easeInOut"}]'
          data-textAlign="['center','center','center','center']"
          data-paddingtop="[10,10,10,10]"
          data-paddingright="[10,10,10,10]"
          data-paddingbottom="[10,10,10,10]"
             data-paddingleft="[10,10,10,10]" style="z-index: 7; text-transform:left;"> Workshop On Towards Human-Centric </br> Image/Video Synthesis </br>
          <div style="font-size: 2.5vw ! important;">and the 4th Look Into Person (LIP) Challenge</div>
          <!--<div style="font-size: 1vw ! important;">June 14th - 19th, 2020 Seattle, WA</div>-->
          <!--and 2D/3D Synthesis Synthesis, <br>-->
          <!--and the third Look Into Person (LIP) Challenge-->
        </div>
<!-- LAYER NR. 4 -->
<!--        <div class="tp-caption NotGeneric-Title   tp-resizeme" 
           id="slide-1699-layer-1" 
           data-x="['center','center','center','center']" data-hoffset="['0','0','0','0']" 
           //data-y="['middle','middle','middle','middle']" 
             data-voffset="['0','0','-22','-29']" 
                data-fontsize="['70','70','70','50']"
          data-lineheight="['42','42','42','30']"
          data-width="none"
          data-height="none"
          data-whitespace="nowrap"
     
          data-type="text" 
          data-responsive_offset="on" 

          data-frames='[{"from":"z:0;rX:0deg;rY:0;rZ:0;sX:1.5;sY:1.5;skX:0;skY:0;opacity:0;","mask":"x:0px;y:100px;","speed":1500,"to":"o:1;","delay":1000,"ease":"Power3.easeInOut"},{"delay":"wait","speed":1000,"to":"y:[100%];","mask":"x:inherit;y:inherit;","ease":"Power2.easeInOut"}]'
          data-textAlign="['center','center','center','center']"
          data-paddingtop="[10,10,10,10]"
          data-paddingright="[0,0,0,0]"
          data-paddingbottom="[10,10,10,10]"
          data-paddingleft="[0,0,0,0]"

          style="z-index: 7; white-space:pre;text-transform:left;"><a href="http://cvpr2017.thecvf.com/">--in conjunction with CVPR 2017,Honolulu,Hawaii,USA,July 21,2017</a></div>
 -->
    
        <!-- LAYER NR. 5 -->
        <div class="tp-caption NotGeneric-CallToAction rev-btn " 
           id="slide-1699-layer-7" 
           data-x="['center','center','center','center']" data-hoffset="['0','0','0','0']" 
           data-y="['middle','middle','middle','middle']" data-voffset="['180','180','80','65']" 
                data-width="none"
          data-height="none"
          data-whitespace="nowrap"
          onmouseover="this.style.cursor='pointer'" onclick="document.location='#portfolio';"
          href="page.html"
          data-type="button" 
          data-actions='[{"event":"click","action":"#portfolio",  "offset":"0px","delay":""}]'
          data-responsive_offset="on" 
          data-responsive="off"
          data-frames='[{"from":"y:50px;opacity:0;","speed":1500,"to":"o:1;","delay":1250,"ease":"Power4.easeInOut"},{"delay":"wait","speed":1000,"to":"y:[175%];","mask":"x:inherit;y:inherit;s:inherit;e:inherit;","ease":"Power2.easeInOut"},{"frame":"hover","speed":"300","ease":"Power1.easeInOut","to":"o:1;rX:0;rY:0;rZ:0;z:0;","style":"c:rgba(255, 255, 255, 1.00);bc:rgba(255, 255, 255, 1.00);bw:1px 1px 1px 1px;"}]'
          data-textAlign="['left','left','left','left']"
          data-paddingtop="[10,10,10,10]"
          data-paddingright="[30,30,30,30]"
          data-paddingbottom="[10,10,10,10]"
          data-paddingleft="[30,30,30,30]"

          style="z-index: 9; white-space: nowrap;text-transform:left;outline:none;box-shadow:none;box-sizing:border-box;-moz-box-sizing:border-box;-webkit-box-sizing:border-box;cursor:pointer;">ABOUT US </div>
      </li>
    </ul>
    <div class="tp-bannertimer tp-bottom" style="visibility: hidden !important;"></div> </div>
    </div><!-- END REVOLUTION SLIDER -->
</header>

<!-- Portfolio -->
<section id="portfolio" class="portfolio">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <header class="section-header">
          <h3 class="section-title" data-text="">Introduction</h3>
         <!-- <div class="panel panel-default">
            <div class="panel-body">-->
              <p style="text-align:justify; white-space: pre-wrap;font-size: 1.2em;">&nbsp;&nbsp;&nbsp;&nbsp;Human-centric image/video synthesis has been intensely researched in computer vision, with the wide application domains such as human motion transfer, virtual try-on, virtual reality, and human-computer interaction. Developing solutions to understand the human-centric image/video synthesis in the practicable scenarios, regarded as one of the most fundamental problems in computer vision, could have a crucial impact in many industrial application domains. Those bring great convenience for the public. However, there exists a large gap between the human-centric synthesis technique and its carrying out applied in the practical scenarios. What is needed by the real-life applications? What is achievable based on modern computer vision techniques? Those all raise the researchers’ attentions and discussions. More human image synthesis, virtual try-on, and 3D graphic analysis research advances are urgently expected for advanced human-centric synthesis. For example, the 2D/3D clothes virtual try-on simulation system that seamlessly fits various clothes into 3D human body shape has attracted numerous commercial interests. The human motion synthesis and prediction can bridge the virtual and real worlds, such as, simulating virtual characters to mimic the human behaviors, empowering robotics more intelligent interactions with human by enabling causal inferences for human activities. The goal of this workshop is to allow researchers from the fields of human-centric image/video synthesis to present their progress, communication and co-develop novel ideas that potentially shape the future of this area and further advance the performance and applicability of correspondingly built systems in real-world conditions. This workshop is designed to build up consensus on the emerging topic of the human-centric image/video synthesis, by clarifying the motivation, the typical methodologies, the prospective trends, and the potential industrial applications.
              </p>
              <!--<p style="text-align:justify; white-space: pre-wrap;font-size: 1.2em;">&nbsp;&nbsp;&nbsp;&nbsp;To stimulate the progress on this research topic and attract more researchers to work on this topic, we also organize the forth large-scale Look Into Person (LIP) challenge which includes four competition tasks: multi-person human parsing, multi-person video parsing, image-baesd multi-pose virtual try-on, and video virtual try-on. This fourth LIP challenge mainly extends the third LIP challenge in CVPR 2017, CVPR 2018, and CVPR 2019 by additionally covering a video virtual try-on challenge. For the multi-person human parsing competition task, we will provide 38280 images of crowded scenes with 19 semantic human part labels. For video-based human parsing, 404 video shots with 1-2 minutes will be densely annotated with 19 semantic human part labels. The image-based multi-pose virtual try-on benchmark targets at fitting new in-shop clothes into a person image and show different clothes viewpoints of the person. The benchmark contains 35,687/13,524 person/clothes images and we will split them into 52,236/10,544 person-clothes-pose three-tuples for training/testing, respectively. Our new video virtual try-on challenge aims to transfer the in-shop clothes to a person and generate a virtual try-on video according to a pose sequence. We reasele a new video virtual try-on benchmark which contains 661/130 videos and 160492/31191 frames for training/testing, respectively. In terms of the quality of the image-based multi-pose virtual try-on and video virtual try-on, the quantitative performance will be given via a human subjective perceptual study on AMT platform. The images collected from the real-world scenarios contain humans appearing with challenging poses and views, heavily occlusions, various appearances and low-resolutions. Details about the datasets are available at this link <a href="http://47.100.21.47:9999/index.php" style="color: blue;">LIP</a>. The challenge is conjunction with <a href="http://cvpr2020.thecvf.com/" style="color: blue;">CVPR 2020</a>, Seattle, WA. Challenge participants with the most successful and innovative entries will be invited to present on this workshop. -->
              <!--</p>-->
              <!--<p style="text-align:justify; white-space: pre-wrap;font-size: 1.2em;">Regarding the viability of this workshop, the topic of this workshop is attractive and active. It is very possible that many active researchers would like to attend this workshop (actually the expected number of attendees is 100 from a conservative estimation based on the past publication record on related topics). It is related to yet still clearly different from past workshops as explained below. In addition, we have got confirmation from many renowned professors and researchers in this area and they are either glad to give a keynote speech (as listed in the program) or kindly offer help. We believe this workshop will be a very successful one and it will indeed benefit the progress of this research area significantly.-->
              <!--</p>-->
        </header>
      </div>
    </div>
  </div>
</section>

<HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="90%" color=#987cb9 SIZE=3>

<!--
&lt;!&ndash; About &ndash;&gt;
<section id="acceptedpapers" class="about">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <header class="section-header">
          <h3 class="section-title font-lg" data-text="">Accepted Papers</h3>

          <ul class="lsit-group" style="text-align: left;font-size: 1.2em; padding-left:0 ">
            <li class="list-group-item">
              <b>Multi-scale Aggregation R-CNN for 2D Multi-person Pose Estimation.</b>
Gyeongsik Moon (Seoul National University)*; Ju Yong Chang (Kwangwoon University); Kyoung Mu Lee (Seoul National University)

            </li>
            <li class="list-group-item">
              <b>Skepxels: Spatio-temporal Image Representation of Human Skeleton Joints for Action Recognition.</b>
Jian Liu (The University of Western Australia)*; Naveed Akhtar (The University of Western Australia); Ajmal Mian (University of Western Australia)

            </li>
            <li class="list-group-item">
              <b>Exploiting Offset-guided Network for Pose Estimation and Tracking.</b>
Rui Zhang (Beijing University of Posts and Telecommunications); Zheng Zhu (Institute of Automation, Chinese Academy of Sciences)*; Peng Li (Horizon robotic); Rui Wu (Horizon Robotics); Chaoxu Guo (Institue of Automation, Chinese Academy of Science); Guan Huang (Horizon Robotics); Hailun Xia (Beijing University of Posts and Telecommunications)

            </li>
            <li class="list-group-item">
              <b>On the Robustness of Human Pose Estimation.</b>
Naman Jain (Indian Institute Of Technology Bombay)*; Sahil H Shah (Indian Institute of Technology Bombay); Abhishek Sharma (Gobasco AI Labs); Arjun Jain (Indian Institute Of Technology Bombay)

            </li>
            <li class="list-group-item">
              <b>Infant Contact-less Non-Nutritive Sucking Pattern Quantification via Facial Gesture Analysis.</b>
Xioafei Huang (Northeastern University); Alaina Martens (Northeastern University); Emily Zimmerman (Northeastern University); Sarah Ostadabbas (Northeastern University)*

            </li>
            <li class="list-group-item">
              <b>Unpaired Pose Guided Human Image Generation.</b>
Xu Chen (ETH Zürich)*; Jie Song (ETH Zurich); Otmar Hilliges (ETH Zurich)

            </li>
            <li class="list-group-item">
              <b>What Elements are Essential to Recognize Human Actions?</b>
Yachun Li (Zhejiang University)*; Yong Liu (Zhejiang University); Chi Zhang (Megvii Inc.)
            </li>
            <li class="list-group-item">
              <b>Patch-based 3D Human Pose Refinement.</b>
Qingfu Wan (Fudan University)*; Weichao Qiu (Johns Hopkins University); Alan Yuille (Johns Hopkins University)

            </li>
            <li class="list-group-item">
              <b>Towards Real-time Sign Language Interpreting Robot: Evaluation of Non-manual Components on Recognition Accuracy.</b>
Arman Sabyrov (Nazarbayev University); Medet Mukushev (Nazarbayev University); Alfarabi Imashev (Nazarbayev University); Kenessary Koishybay (Nazarbayev University); Anara Sandygulova (Nazarbayev University)*; Vadim Kimmelman (University of Bergen)

            </li>
          </ul>
        </header>

      </div>
    </div>
  </div>
</section>



&lt;!&ndash; About &ndash;&gt;
<section id="winners" class="about">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <header class="section-header">
          <h3 class="section-title font-lg" data-text="">Challenge Winners</h3>

          <ul class="lsit-group" style="text-align: left;font-size: 1.2em; padding-left:0 ">
            <li class="list-group-item">
              <b>Track 1: Single-Person Human Parsing Challenge Winners:<br></b>
              1st:<br>
              Peike Li1, 2,  Yunqiu Xu1,  Yi Yang1, 2 <br>
              1Baidu Research, 2CAI, University of Technology Sydney<br>
              <br>
              2nd:<br>
              Dongdong Yu1, *, Kai Su1, 2, *, Jian Wang1, Kaihui Zhou1 , Xin Geng2 , Changhu Wang1<br>
              1ByteDance AI Lab, 2Southeast University<br>
              <br>
              3rd:<br>
              Zhijie Zhang1, Wenguan Wang2, Jianbing Shen2, Siyuan Qi3, Yanwei Pang1 , Ling Shao2<br>
              1Tianjin University, 2Inception Institute of Artificial Intelligence,3UCLA <br>

            </li>
            <li class="list-group-item">
              <b>Track 2: Single-Person Human Pose Estimation Challenge Winners:<br></b>
              1st:<br>
              Kai Su1, 2, *, Dongdong Yu1, *, Xin Geng2 , Changhu Wang1<br>
              1ByteDance AI Lab, 2Southeast University<br>
              <br>
              1st:<br>
              Bin Xiao, Yifan Lu, Tang Tang, Hao Zhu, Linfu Wen<br>
              ByteDance AI Lab<br>
              <br>
              3rd:<br>
              Juan Manuel Pérez Rúa, Kaiyang Zhou, Adrian Bualt, Xiatian Zhu, Tao Xiang, Maja Pantic <br>
              Samsung AI Center - Cambridge, UK<br>
              <br>
              3rd:<br>
              Hong Hu, Feng Zhang, Hanbin Dai, Huan Luo, LiangBo Zhou, Mao Ye <br>
              University of Electronic Science and Technology of China(UESTC)<br>
            </li>
            <li class="list-group-item">
              <b>Track 3: Multi-Person Human Parsing Challenge Winners: <br></b>
              1st: <br>
              Yunqiu Xu1,  Peike Li1, 2,  Yi Yang1, 2  <br>
              1Baidu Research, 2CAI, University of Technology Sydney <br>
               <br>
              2nd: <br>
              Meng Zhang1, Xinchen Liu2, Wu Liu2, Anfu Zhou1, Huadong Ma1, Tao Mei2  <br>
              1Beijing University of Posts and Telecommunications,  <br>
              2AI Research of JD.com <br>
              <br>
              3rd: <br>
              Bingke Zhu1, 2, Xiaomei Zhan1, 2, Yingying Chen1, 2, Ming Tang1, 2, <br>
              Hui Li3, Ting Zhang3, Zhaoliang Zhang3, Wenjie Tang3, Jinqiao Wang1, 2  <br>
              1National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, <br>
              2University of Chinese Academy of Sciences, <br>
              3R&D Center, China National Electronics Import & Export Corporation <br>

            </li>
            <li class="list-group-item">
              <b>Track 4: Video Multi-Person Human Parsing Challenge Winners:<br></b>
              1st:<br>
              Peike Li1, 2,  Yunqiu Xu1,  Yi Yang1, 2 <br>
              1Baidu Research, 2CAI, University of Technology Sydney<br>
              <br>
              2nd:<br>
              Jianhua Sun1, *, Dian Shao2, *, Hao-Shu Fang1, Cewu Lu1 <br>
              1Shanghai Jiao Tong University, 2The Chinese University of Hong Kong<br>

            </li>
            <li class="list-group-item">
              <b>Track 5: Image-based Multi-pose Virtual Try-on Challenge Winners:<br></b>
              1st:<br>
              Rokkyu Lee, Hyugjae Lee, Minseok Kang, Gunhan Park<br>
              NHN<br>
              <br>
              2nd:<br>
              Yu Sun, Wu Liu, Qian Bao, Yuhao Cheng, Tao Mei <br>
              JD AI Human<br>

            </li>

          </ul>
        </header>

      </div>
    </div>
  </div>
</section>






&lt;!&ndash; About &ndash;&gt;
<section id="poster" class="about">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <header class="section-header">
          <h3 class="section-title font-lg" data-text="">Posters</h3>
          <ul class="lsit-group" style="text-align: left;font-size: 1.2em; padding-left:0 ">
            <li class="list-group-item">
              <b>Location: Note that the workshop posters will be in the Pacific Arena Ballroom (main convention center).<br></b>
            </li>
          <ul class="lsit-group" style="text-align: left;font-size: 1.2em; padding-left:0 ">
            <li class="list-group-item">
              <b>10:00 - 11:00 AM:<br></b>
              Poster Numbers: #34 – 38 <br>
              #34: paper 3,  #35: paper 7, #36 paper 9, <br>
              #37:paper 11, #38: paper 14<br>

            </li>
            <li class="list-group-item">
              <b>3:15 - 4:00 PM<br></b>
              Poster Numbers: #34 – 38 <br>
              #34: paper 16,  #35: paper 21, #36 paper 22, <br>
              #37:paper 26    <br>
            </li>


          </ul>
        </header>

      </div>
    </div>
  </div>
</section>

-->



<!-- About -->
<section id="about" class="about">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <header class="section-header">
          <h3 class="section-title font-lg" data-text="">Topics of interest</h3>
          
          <h4 style="text-align:left;">&nbsp;&nbsp;The submission are expected to deal with human-centric visual perception and processing tasks which include but are not limited to:</h4>
          <ul class="lsit-group" style="text-align: left;font-size: 1.2em; padding-left:0 ">
            <li class="list-group-item">
              2D/3D Clothes Virtual Try-on System
            </li>
            <li class="list-group-item">
              Fashion image manipulation
            </li>
            <li class="list-group-item">
              Human motion transfer
            </li>
            <li class="list-group-item">
              Human body 3D shape estimation and simulation
            </li>
            <li class="list-group-item">
              2D/3D human pose estimations from video
            </li>
            <li class="list-group-item">
              Human action recognition and trajectory recognition/prediction
            </li>
            <li class="list-group-item">
              Human clothing and attribute recognition
            </li>
            <li class="list-group-item">
               Novel datasets for performance evaluation and/or empirical analyses of existing methods
            </li>
            <li class="list-group-item">
              3D human body shape estimation and simulation
            </li>
            <li class="list-group-item">
              Advanced applications of human augment, including autonomous cars, event recognition and prediction, robotic manipulation, indoor navigation, image/video retrieval and virtual reality.
            </li>

          </ul>
        </header>
        
      </div>      
    </div>
  </div>
</section>

<!-- Call To Action -->
<!-- <section class="call-to">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <article class="action">
          <h5>Intrested about us?</h5>
          <a href="http://sysu-hcp.net/lip" class="btn btn-border" role="button">Learn More</a>
        </article>
      </div>
    </div>
  </div>
</section> -->

<HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="90%" color=#987cb9 SIZE=3>
<!-- Blog -->
<section id="blog" class="blog">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <header class="section-header">
          <h3 class="section-title" data-text="" style="text-align: center;">Tentative SCHEDULE</h3>
        </header>
        <body>
          <table class="table table-hover table-condesed">
            <colgroup>
              <col width="40%">
              <col width="60%">
            </colgroup>
             <thead style="font-size: 1.3em">
              <tr  class="blue_bottom">  
                <th> 
                  <h4 style="font-weight: bolder;text-align: center;color: #165ac5">Time</h4>
                </th>
                <th>
                  <h4 style="font-weight: bolder;color: #165ac5">Schedule</h4>
                </th>
              </tr>
             </thead>
            <tbody style="font-size: 1.2em">
              <tr>
                <td style="color:red; text-align: center;font-weight:bolder;">Location: </td>
                <td style="color:red;">Date: Friday, 19 June 2020 from 13:30PM to 18:00PM</td>
              </tr>
              <!-- <tr>
                <td style="text-align: center;font-weight:bolder;"><ul>Conference Country: United States of America</ul></td>
              </tr> -->
              <tr>
               <td style="text-align: center;font-weight:bolder;">13:30-13:40</td>
               <td>Opening remarks and welcome</td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">13:40-14:00</td>
                <td>The Look Into Person (LIP) challenge introduction and results</td>
              </tr>
              <tr>
               <td style="text-align: center;font-weight:bolder;">14:00-14:20</td>
               <td>Oral talk 1: Winner of multi-person / video human parsing challenge</td>
              </tr>
               <tr>
                <td style="text-align: center;font-weight:bolder;">14:20-15:00</td>
                <td>Invited talk 1:</td>
              </tr>
              <!--<tr>-->
                <!--<td style="text-align: center;font-weight:bolder;">09:15-10:00</td>-->
                <!--<td>Invited talk 1: <strong>Alan L. Yuille, Professor, Johns Hopkins University</strong></td>-->
              <!--</tr>-->
              <tr>
               <td style="text-align: center;font-weight:bolder;">15:00-15:40</td>
               <td>Invited talk 2:</td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;vertical-align: middle;">15:40-16:00</td>
                <td>Oral talk 2: Winner of the image-based multi-pose virtual try-on challenge</td>
              </tr>
              <!--<tr>-->
                <!--<td style="text-align: center;font-weight:bolder;vertical-align: middle;">10:30-11:15</td>-->
                <!--<td>Invited talk 2: <strong>Alexei (Alyosha) Efros, Professor, UC Berkeley</strong></td>-->
              <!--</tr>-->
              <!-- <tr>
                <td style="text-align: center;font-weight:bolder;">11:15-11:45</td>
                <td>Invited talk 3: Alan Yuille, Johns Hopkins University</td>
              </tr> -->
              <tr>
               <td style="text-align: center;font-weight:bolder;">16:00-16:30</td>
                <td>Poster session and coffee break</td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">16:30-17:00</td>
                <td>Invited talk 3:</td>
              </tr>
              <!-- <tr>
               <td style="text-align: center;font-weight:bolder;">11:15-11:30</td>
               <td>Oral talk 2: Winner of single-person pose estimation challenge</td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">11.30-11.45</td>
                <td>Oral talk 3: Winner of multi-person human parsing challenge</td>
              </tr> -->
              <!-- <tr>
                <td style="text-align: center;font-weight:bolder;">11:45-12:00</td>
                <td>Oral talk 4: Winner of video parsing challenge</td>
              </tr> -->
              <tr>
               <td style="text-align: center;font-weight:bolder;">17:00-17:30</td>
               <td>Invited talk 4:</td>
              </tr>
              <!-- <tr>
                <td style="text-align: center;font-weight:bolder;">14:00-14:30</td>
                <td>Invited talk 3: Trevor Darrell, UC Berkeley</td>
              </tr> -->
              <tr>
                <td style="text-align: center;font-weight:bolder;">17:30-18:00</td>
                <td>Awards & Future Plans</td>
              </tr>
              <!-- <tr>
               <td style="text-align: center;font-weight:bolder;">14:00-14:15</td>
               <td>Oral talk 2: Winner of single-person(Track 3) & multi-person(Track 4) pose estimation challenge, Speaker: Wu Liu(JD AI Research)</td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">14.15-14.30</td>
                <td>Oral talk 3: Winner of single-person(Track 1) & multi-person(Track 2 & Track 5) human parsing challenge, Speaker: Yunchao Wei(University of Illinois Urbana-Champaign)</td>
              </tr> -->
              <!-- <tr>
                <td style="text-align: center;font-weight:bolder;">14:00-14:30</td>
                <td>Invited talk 4: <strong>Jianchao Yang, Director, ByteDance AI Lab.</strong></td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">14:30-14:45</td>
                <td>Oral talk 4: Winner of image-based multi-pose virtual try-on challenge</td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">14:45-16:15</td>
                <td>Poster session and coffee break</td>
              </tr> -->
              <!--<tr>-->
               <!--<td style="text-align: center;font-weight:bolder;">15:15-15:45</td>-->
                <!--<td>Invited talk 6: <strong>Katerina Fragkiadaki, Assistant Professor, CMU</strong></td>-->
              <!--</tr>-->
              <!-- <tr>
               <td style="text-align: center;font-weight:bolder;">16:15-16:45</td>
                <td>Invited talk 5: <strong>Katerina Fragkiadaki, Assistant Professor, CMU</strong></td>
              </tr>
              <tr>
                <td style="text-align: center;font-weight:bolder;">16:45-17:15</td>
                <td>Awards & Future Plans</td>
              </tr> -->
              <!--<tr>-->
                <!--<td style="text-align: center;font-weight:bolder;">15:45-16:15</td>-->
                <!--<td>Invited talk 7: <strong>Chunhua Shen, Professor, University of Adelaide</strong></td>-->
              <!--</tr>-->
              <!--<tr>-->
                <!--<td style="text-align: center;font-weight:bolder;">16:15-16:45</td>-->
                <!--<td>Awards & Future Plans</td>-->
              <!--</tr>-->
            </tbody>
          </table>
        <!-- TBD. -->
        </body>
      </div>
    </div>
  </div>
</section>
<!-- ********************************************************************************************************** -->

<HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="90%" color=#987cb9 SIZE=3>
<!-- call for papers -->
<section id="papers" class="portfolio">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <header class="section-header">
          <h3 class="section-title" data-text="">Call for Papers</h3>
          <table class="table">
            <caption style="font-weight: bolder;text-align: center;color: black;font-size:1.3em"><br>Paper Submission<br><br></caption>
           
            <tbody style="font-size: 1.2em">
              <tr>
                <td style="font-weight: bolder;color: black;vertical-align: middle;">Important Dates</td>
              </tr>
              <tr>
                <!-- <td style="text-align: justify;">
                Paper reviewing is double-blind. So please avoid providing information that may identify the authors in the acknowledgments (e.g., co-workers and grant IDs) and in the supplemental material (e.g., titles in the movies, or attached papers). Avoid providing links to websites that identify the authors. Please read the example paper <a href="http://cvpr2017.thecvf.com/files/egpaper_for_review.pdf" style="color: blue;font-weight: bold;">egpaper_for_review.pdf</a> for detailed instructions on how to preserve anonymity.
                </td> -->
              </tr>
              <!-- <tr>
                <td style="font-weight: bolder;color: black;font-size:1.1em;vertical-align: middle;">Requirements</td>
              </tr> -->
              <!--<tr>-->
              <!--<td><ul>Paper Submission Due Date: April 15, 2019, 11:59 PM PST</ul></td>-->
              <!--</tr>-->
              <tr>
                <td><ul>Paper Submission Due Date: <s>April 1, 2020  [11:59 p.m. PST]</s> <font color="red">April 15, 2020  [11:59 p.m. PST]</font></ul></td>
              </tr>
              <!--<tr>-->
                <!--<td><ul>Review Due: May 1, 2019</ul></td>-->
              <!--</tr>-->
              <tr>
                <td><ul>Notification of Acceptance/Rejection: <s>April 7, 2020  [11:59 p.m. PST]</s> <font color="red">April 17, 2020  [11:59 p.m. PST]</font></ul></td>
              </tr>
              <tr>
                <td><ul>Camera-Ready Due Date: <s>April 15, 2020  [11:59 p.m. PST]</s> <font color="red">April 19, 2020  [11:59 p.m. PST]</font></ul></td>
              </tr>
              <!--<tr>-->
                <!--<td><ul>Conference Date: 06/18/2018 </ul></td>-->
              <!--</tr>-->
            <!--   <tr>
                <td style="text-align: justify;">⑤ If your submission has co-authors, please make sure that you enter their email addresses that correspond exactly to their account names (assuming they have created accounts). This will ensure that your co-authors can see your submission when they log in. Co-authors must also have their conflict domains entered.</td>
              </tr> -->
              <tr>
                <td style="font-weight: bolder;color: black;font-size:1.1em;vertical-align: middle;">Format Requirements</td>
              </tr>
              <tr>
                <!--<td>Format: <b> <font color="red">Papers that are at most 4 pages *including references* do not count as a dual submission. Workshop papers that are reviewed and longer than 4 pages do count as a publication, including figures and tables, in the CVPR style. </font></b></ul></td>-->
                <td>Format: <b> <font color="red">Papers that are at least 4 pages (excluding references), in the CVPR style. </font></b></ul></td>
              </tr>
              <tr>
                <td><ul>Example submission paper with detailed instructions: <a target="_blank" style="color:blue;" href="http://cvpr2020.thecvf.com/sites/default/files/2019-09/egpaper_for_review.pdf">http://cvpr2020.thecvf.com/sites/default/files/2019-09/egpaper_for_review.pdf</a></ul></td>
              </tr>
              <tr>
                <td><ul>LaTeX/Word Templates(tar): <a target="_blank" style="color:blue;" href="http://cvpr2020.thecvf.com/sites/default/files/2019-09/cvpr2020AuthorKit.tar">http://cvpr2020.thecvf.com/sites/default/files/2019-09/cvpr2020AuthorKit.tar</a></ul></td>
              </tr>
              <tr>
                <td><ul>LaTeX/Word Templates(zip): <a target="_blank" style="color:blue;" href="http://cvpr2020.thecvf.com/sites/default/files/2019-09/cvpr2020AuthorKit.zip">http://cvpr2020.thecvf.com/sites/default/files/2019-09/cvpr2020AuthorKit.zip</a></ul></td>
              </tr>
              <tr>
                <td><ul>A complete paper should be submitted using the above templates, which are blind-submission review-formatted templates. The length should match that intended for final publication. </ul></td>
              </tr>


              <tr>
                <td style="font-weight: bolder;color: black;font-size:1.1em;vertical-align: middle;">Submission Details</td>
              </tr>
              <tr>
                <td><ul>Paper Submission Site: <a target="_blank" style="color:blue;" href="https://cmt3.research.microsoft.com/VUHCS2020">https://cmt3.research.microsoft.com/VUHCS2020</a></ul></td>
              </tr>
              <tr>
                <td><ul>Conference City: Seattle, WA</ul></td>
              </tr>
              <tr>
                <td><ul>Conference Country: United States of America</ul></td>
              </tr>

              <!-- <tr>
                <td style="font-weight: bolder;color: black;font-size:1.1em;vertical-align: middle;">Others</td>
              </tr> -->
              <!-- <tr>
                <td style="text-align: justify;">All the papers must be submitted in IEEE format using the <a href="http://cvpr2017.thecvf.com/files/cvpr2017AuthorKit.zip" style="color: blue;font-weight: bold;">templates</a> provided. Submitted papers should not have been published, accepted or under review elsewhere.</td>
              </tr>
              <tr>
                <td style="text-align: justify;">For more detailed instructions for paper submission, please consult <a href="http://cvpr2018.thecvf.com/submission/main_conference/author_guidelines" style="color: blue;font-weight: bold;">CVPR 2018</a> web page.</td>
              </tr>
              <tr>
                <td >All the papers should be submitted at our <a href="https://cmt3.research.microsoft.com/VUHCS2017" style="color: blue;font-weight: bold;text-decoration: underline;">CMT site</a>.</td>
              </tr> -->
            </tbody>
          </table>
          <table class="table">
            <caption style="font-weight: bolder;text-align: center;color: black;font-size:1.3em"><br>Best Paper Award<br><br></caption>
          
            <tbody style="font-size: 1.2em">
              <tr>
                <td><ul>We set the Best Paper Award for one outstanding paper from all of the accepted papers for its novelty and significant contribution. </ul> </td>
              </tr>
            </tbody>
          </table>
        </header>
      </div>
    </div>
  </div>
</section>

<section id="challenge" class="portfolio">
    <div class="container">
    <div class="row">
      <div class="col-md-12">
        <header class="section-header">
          <h3 class="section-title" data-text="">Challenges</h3>
          <!-- TBD. -->
          <table class="table">
            <caption style="font-weight: bolder;text-align: center;color: black;font-size:1.3em"><br><br>Challenge Submission<br><br></caption>
           
            <thead style="font-size: 1.2em">
              <tr>
                <td style="font-weight: bolder;color: black;vertical-align: middle;">Important Dates</td>
              </tr>
            </thead>
            <tbody style="font-size: 1.3em ">

            </tr>
              <tr>
              <!--&lt;!&ndash; <td><ul> <font style="font-weight: bold;">Track1~3</font> Due Date (mm/dd/yyyy): 06/04/2018 23:59 UTC/GMT+0</ul></td> &ndash;&gt;-->
                <td>
                  <ul>Challenge Submission Due Date: <s>May 20, 2020, 11:59 PM GMT</s>
                  <font color="red">Extend to June 5, 2020, 11:59 PM GMT</font>
                  <!--<tr>Our new website is: </tr><br>-->
                  <!--<a href="http://47.100.21.47:9999/index.php"  target="_blank"> http://47.100.21.47:9999/index.php </a>-->

                  <br></ul></td>
              </tr>
              <!--&lt;!&ndash; <tr>-->
              <!--<td><ul> <font style="font-weight: bold;">Track4~5</font> Due Date (mm/dd/yyyy): 05/31/2018 23:59 UTC/GMT+0<br><br></ul></td>-->
              <!--</tr> &ndash;&gt;-->
              <!---->
            </tbody>
          </table>
          <div class="list-group">
            <a href="https://competitions.codalab.org/competitions/23431"  target="_blank" class="list-group-item">
              <h4 class="list-group-item-heading" style="font-weight: bolder;">
                Track1
              </h4>
              <p class="list-group-item-text">
                Look Into Person: Multi-Person Human Parsing Challenge
              </p>
            </a>
              <a href="https://competitions.codalab.org/competitions/23433"  target="_blank" class="list-group-item">
              <h4 class="list-group-item-heading" style="font-weight: bolder;">
                Track2
              </h4>
              <p class="list-group-item-text">
                Look Into Person: Video Mutil-Person Human Parsing Challenge
              </p>
            </a>
              <a href="https://competitions.codalab.org/competitions/23471"  target="_blank" class="list-group-item">
              <h4 class="list-group-item-heading" style="font-weight: bolder;">
                Track3
              </h4>
              <p class="list-group-item-text">
                Look Into Person: Image-based Multi-pose Virtual Try-on Challenge
              </p>
            </a>
            <a href="https://competitions.codalab.org/competitions/23472" target="_blank"  class="list-group-item">
              <h4 class="list-group-item-heading" style="font-weight: bolder;">
                Track4
              </h4>
              <p class="list-group-item-text">
                Look Into Person: Video Virtual Try-on Challenge
              </p>
            </a>
            <a href="https://competitions.codalab.org/competitions/24206" target="_blank"  class="list-group-item">
              <h4 class="list-group-item-heading" style="font-weight: bolder;">
                Track5
              </h4>
              <p class="list-group-item-text">
                Look Into Person: Dark Complexion Portrait Segmentation Challenge
              </p>
            </a>
            <!--<a href="http://sysu-hcp.net/lip"  target="_blank" class="list-group-item">-->
              <!--<h4 class="list-group-item-heading" style="font-weight: bolder;">-->
                <!--Track5-->
              <!--</h4>-->
              <!--<p class="list-group-item-text" >-->
                <!--Look Into Person: Image-based Multi-pose Virtual Try-on-->
              <!--</p>-->
            <!--</a>-->
            <!-- <a href="https://lv-mhp.github.io/" target="_blank" class="list-group-item">
              <h4 class="list-group-item-heading" style="font-weight: bolder;">
                Track4
              </h4>
              <p class="list-group-item-text">
                Pose Estimation
              </p>
            </a> -->
            <!--<a href="https://lv-mhp.github.io/" target="_blank" class="list-group-item">-->
              <!--<h4 class="list-group-item-heading" style="font-weight: bolder;">-->
                <!--Track4-->
              <!--</h4>-->
              <!--<p class="list-group-item-text">-->
                <!--Look Into Person: Multi-Human Pose Estimation Challenge(25403 images)-->
              <!--</p>-->
            <!--</a>-->
            <!--<a href="https://lv-mhp.github.io/" target="_blank" class="list-group-item">-->
              <!--<h4 class="list-group-item-heading" style="font-weight: bolder;">-->
                <!--Track5-->
              <!--</h4>-->
              <!--<p class="list-group-item-text">-->
                <!--Look Into Person: Fine-Grained Multi-Human Human Parsing Challenge(25403 images)-->
              <!--</p>-->
            <!--</a>-->
            <!--<a class="list-group-item">-->
              <!--<div class="row">-->
                  <!--<div class="col-md-6 col-xs-6  col-md-offset-1 " href="http://sysu-hcp.net/lip"  target="_blank">-->
                    <!--<img src="img/SYN.png" class="list-group-item-heading" style="padding-top: 2em" >-->
                  <!--</div>-->
                  <!--&lt;!&ndash;<div class="col-md-2 col-xs-6 " href="https://lv-mhp.github.io/" target="_blank">&ndash;&gt;-->
                    <!--&lt;!&ndash;<img src="img/FENGG.png" class="list-group-item-heading" style="padding-bottom: 2em " >&ndash;&gt;-->
                <!--&lt;!&ndash;</div>&ndash;&gt;-->
              <!--</div> -->
            <!--</a>   -->
          </div>
        </header>
      </div>
    </div>
  </div>
</section>

<!-- ********************************************************************************************************** -->
<HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="90%" color=#987cb9 SIZE=3>
<!-- Team -->
<section id="team" class="team">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <header class="section-header">
          <h3 class="section-title" data-text="">Main Organizers</h3>
        </header>
      </div>
    </div>

    <div class="row">

      <div class="col-sm-4 col-md-2 col-md-offset-2">
            <img src="img/team/xiaodan3.jpg" class="img-circle img-responsive img-thumbnail center-block" alt="img">
          <h5 class="member-name"  data-text="Associate Professor, Sun Yat-sen University"><a href="https://lemondan.github.io" target="_blank" style="white-space: pre-wrap;">Xiaodan Liang</a><br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;xdliang328@gmail.com</font></span></h5>
      </div>
      <div class="col-sm-4 col-md-2 col-md-offset-1">
          <img src="img/team/haoye.jpg" class="img-circle img-responsive img-thumbnail center-block" alt="img">
        <h5 class="member-name"  data-text="Ph.D. student, Sun Yat-sen University"><a href="http://www.scholat.com/donghaoye" target="_blank" style="white-space: pre-wrap;">Haoye Dong</a><br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;donghy7@mail2.sysu.edu.cn</font></span></h5>
      </div>
      <div class="col-sm-4 col-md-2 col-md-offset-1">
            <img src="img/team/xzy.jpg" class="img-circle img-responsive img-thumbnail center-block" alt="img">
          <!-- <h5 class="member-name"   data-text="M.S. Student, Sun Yat-sen University"><a href="#" target="_blank" style="white-space: pre-wrap;">Zhenyu Xie</a><br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;xiezhy6@mail2.sysu.edu.cn</font></span></h5> -->
          <h5 class="member-name"   data-text="M.S. Student, Sun Yat-sen University">Zhenyu Xie<br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;xiezhy6@mail2.sysu.edu.cn</font></span></h5>
        </div>
    </div>

      <div class="col-sm-4 col-md-2 col-md-offset-2">
            <img src="img/team/linliang.jpg" class="img-circle img-responsive img-thumbnail center-block" alt="img">
          <h5 class="member-name"  data-text="Professor, Sun Yat-sen University"><a href="http://www.linliang.net/" target="_blank" style="white-space: pre-wrap;">Liang Lin</a><br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;linliang@ieee.org</font></span></h5>
      </div>
      <div class="col-sm-4 col-md-2 col-md-offset-1">
          <img src="img/team/Jiashi Feng.png" class="img-circle img-responsive img-thumbnail center-block" alt="img">
        <h5 class="member-name"  data-text="Assistant Professor, National University of Singapore"><a href="https://sites.google.com/site/jshfeng/" style="white-space: pre-wrap;">Jiashi Feng</a><br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;elefjia@nus.edu.sg</font></span></h5>
      </div>
      <div class="col-sm-4 col-md-2 col-md-offset-1">
            <img src="img/team/songchun.jpg" class="img-circle img-responsive img-thumbnail center-block" alt="img">
          <h5 class="member-name"   data-text="Professor, University of California, Los Angeles"><a href="http://www.stat.ucla.edu/~sczhu" target="_blank" style="white-space: pre-wrap;">Song-Chun Zhu</a><br><span class="fa-icon-envelope" style="white-space: pre-wrap;"><font size="-1" style="font-weight: normal;text-transform: lowercase;">&nbsp;sczhu@stat.ucla.edu</font></span></h5>
        </div>
    </div>
  </div>
</section>


<HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="90%" color=#987cb9 SIZE=3>
<!-- Blog -->
<section id="association" class="association">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <header class="section-header">
          <h3 class="section-title" data-text="">Contact</h3>
          <p style="text-align: center;font-size: 1.2em;white-space: pre-wrap">Please feel free to send any question or comments to: <br><font color=#0E04F5>donghy7 AT mail2.sysu.edu.cn, xdliang328 AT gmail.com </font>
          </p>
        <!--  <p style="text-align: left;font-size: 1.2em;white-space: pre-wrap; margin-top: -50px">
            &nbsp;&nbsp;&nbsp;&nbsp;You are also welcomed to discuss with us in our googlegroup:<font style="color: blue">lip17-organizers@googlegroups.com</font>
          </p>-->
    
        </header>
      </div>
    </div>
  </div>
</section>

<!-- Footer -->
<footer class="footer">
  <div class="container">
    <div class="row">
      <div class="col-md-12 col-sm-12 center-block" data-animation="zoomIn" data-animation-delay="01">
        <h6><a href="http://sysu-hcp.net/lip">L.I.P</a></h6>
        
<!--        <ul class="social-list">
          <li class="fa-icon-facebook"></li>
          <li class="fa-icon-twitter"></li>
          <li class="fa-icon-pinterest"></li>
          <li class="fa-icon-flickr"></li>
          <li class="fa-icon-dribbble"></li>
          <li class="fa-icon-behance"></li>
        </ul> -->
      </div>
    </div>
  </div>
</footer>


<script src="js/jquery.js"></script>
<script src="js/vendor/fastclick.js"></script>

<script src="js/bootstrap.min.js"></script>

<script src="js/vendor/jquery.appear.js"></script>                  <!-- jQuery Appear -->
<script src="js/vendor/jquery.easing.1.3.js"></script>              <!-- jQuery Easing -->
<script src="js/vendor/imagesloaded.pkgd.min.js"></script>          <!-- Imagesloaded -->
<script src="js/vendor/isotope.pkgd.min.js"></script>               <!-- Isotope -->
<script src="js/vendor/jquery.countTo.js"></script>                 <!-- Count To -->
<script src="js/vendor/jquery.easypiechart.min.js"></script>        <!-- easyPieChart -->
<script src="js/vendor/jquery.magnific-popup.min.js"></script>      <!-- Magnific Popup -->
<script src="js/vendor/owl.carousel.min.js"></script>               <!-- Owl Carousel -->
<script src="js/vendor/jquery.validate.min.js"></script>            <!-- jQuery Validate -->
<script src="js/contact.js"></script>

<script type="text/javascript" src="js/sliders/jquery.themepunch.tools.min.js"></script>
<script type="text/javascript" src="js/sliders/jquery.themepunch.revolution.min.js"></script>

<!-- SLIDER REVOLUTION 5.0 EXTENSIONS  (Load Extensions only on Local File Systems !  The following part can be removed on Server for On Demand Loading) -->    
<script type="text/javascript" src="js/sliders/revolution.extension.actions.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.carousel.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.kenburn.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.layeranimation.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.migration.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.navigation.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.parallax.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.slideanims.min.js"></script>
<script type="text/javascript" src="js/sliders/revolution.extension.video.min.js"></script>

<script src="js/main.js"></script>                                  <!-- Custom jQuery -->
<script src="js/functions.js"></script>                             <!-- Revolution Functions -->

</body>
</html>
